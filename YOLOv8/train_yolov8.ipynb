{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed\n",
    "absolute_path = os.path.dirname('./')\n",
    "relative_path = \"config/\"\n",
    "full_path = os.path.join(absolute_path, relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.134 is required but found version=8.0.157, to fix: `pip install ultralytics==8.0.134`\n",
      "Downloading Dataset Version Zip in building-facade-segmentation-instance-1 to yolov8: 100% [118010965 / 118010965] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to building-facade-segmentation-instance-1 in yolov8:: 100%|██████████| 1208/1208 [00:00<00:00, 4767.91it/s]\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=\"REDACTED\")\n",
    "project = rf.workspace(\"building-facade\").project(\"building-facade-segmentation-instance\")\n",
    "dataset = project.version(1).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new YOLO model\n",
    "model = YOLO('yolov8x-seg.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load finetuned model\n",
    "finetuned_model = YOLO('runs/segment/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (adjust data.yaml with paths)\n",
    "model.train(data='./data.yaml', epochs=1000, imgsz=1024, batch=8, plots=True, device=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.val()  # evaluate model performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder with pictures to apply predictions\n",
    "res = finetuned_model.predict('../../data/unzipped/facade-original-yolo-segmentation/test/images/20230329_200459_677_R_scaled_1_png_jpg.rf.14f294f9e9ede4578aea863866436de0.jpg', save=True, imgsz=1024, conf=0.1, retina_masks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the unnormalized mask (x and y coords according to imgsize)\n",
    "masks=res[0].masks.xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the normalized mask (x and y coords between 0 and 1)\n",
    "masks=res[0].masks.xyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
